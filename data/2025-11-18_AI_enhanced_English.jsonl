{"id": "2511.11552", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11552", "abs": "https://arxiv.org/abs/2511.11552", "authors": ["Dawei Zhu", "Rui Meng", "Jiefeng Chen", "Sujian Li", "Tomas Pfister", "Jinsung Yoon"], "title": "DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding", "comment": null, "summary": "Comprehending long visual documents, where information is distributed across extensive pages of text and visual elements, is a critical but challenging task for modern Vision-Language Models (VLMs). Existing approaches falter on a fundamental challenge: evidence localization. They struggle to retrieve relevant pages and overlook fine-grained details within visual elements, leading to limited performance and model hallucination. To address this, we propose DocLens, a tool-augmented multi-agent framework that effectively ``zooms in'' on evidence like a lens. It first navigates from the full document to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate a single, reliable answer. Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing even human experts. The framework's superiority is particularly evident on vision-centric and unanswerable queries, demonstrating the power of its enhanced localization capabilities.", "AI": {"tldr": "DocLens is a tool-augmented multi-agent framework that addresses evidence localization challenges in long visual documents by navigating from full documents to specific visual elements and using sampling-adjudication for reliable answers.", "motivation": "Existing Vision-Language Models struggle with evidence localization in long visual documents, failing to retrieve relevant pages and missing fine-grained details, which leads to limited performance and model hallucination.", "method": "Proposes DocLens framework that first navigates from full documents to specific visual elements on relevant pages, then employs a sampling-adjudication mechanism to generate reliable answers.", "result": "Paired with Gemini-2.5-Pro, DocLens achieves state-of-the-art performance on MMLongBench-Doc and FinRAGBench-V, surpassing human experts, with particular strength on vision-centric and unanswerable queries.", "conclusion": "DocLens demonstrates superior evidence localization capabilities through its multi-agent framework, effectively addressing fundamental challenges in long visual document comprehension."}}
